@inproceedings{mohammad2015emotion,
  title={Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon},
  author={Mohammad, Saif M. and Turney, Peter D.},
  booktitle={Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
  pages={26--34},
  year={2010}
}

@article{mehrabian1995framework,
  title={Framework for a comprehensive description and measurement of emotional states},
  author={Mehrabian, Albert},
  journal={Genetic, Social, and General Psychology Monographs},
  volume={121},
  number={3},
  pages={339--361},
  year={1995}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{sun2019bert,
  title={Utilizing BERT for aspect-based sentiment analysis via constructing auxiliary sentence},
  author={Sun, Chi and Huang, Luyao and Qiu, Xipeng},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  pages={380--385},
  year={2019}
}

@article{yadav2020sentiment,
  title={Sentiment analysis using deep learning architectures: a review},
  author={Yadav, Suman and Yadav, Shailja},
  journal={Artificial Intelligence Review},
  volume={53},
  number={6},
  pages={4335--4385},
  year={2020}
}

@inproceedings{latif2020deep,
  title={Deep learning for audio-based emotion recognition: A survey},
  author={Latif, Sherry and Rana, R. and Khalifa, S. and Jurdak, R. and Epps, J.},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={--},
  year={2020}
}

@article{akcay2020speech,
  title={Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers},
  author={Ak√ßay, M. B. and O{\u{g}}uz, K.},
  journal={Speech Communication},
  volume={116},
  pages={56--76},
  year={2020}
}

@article{he2020deberta,
  title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@inproceedings{subathra2023comparative,
  title={A Comparative Analysis of Regression Algorithms for Prediction of Emotional States using Peripheral Physiological Signals},
  author={Subathra, P. and Author2, ...},
  booktitle={RAEEUCCII},
  year={2023}
}

@inproceedings{grimm2007svr,
  title={Support Vector Regression for Automatic Recognition of Spontaneous Emotions in Speech},
  author={Grimm, Michael and Kroschel, Kai and Narayanan, Shrikanth},
  booktitle={ICASSP},
  pages={1085--1088},
  year={2007}
}

@article{livingstone2018ryerson,
  title={The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
  author={Livingstone, Steven R. and Russo, Frank A.},
  journal={PloS one},
  volume={13},
  number={5},
  pages={e0196391},
  year={2018}
}

@inproceedings{hsu2021hubert,
  title={{HuBERT}: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
  author={Hsu, Wei-Ning and others},
  booktitle={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2021}
}

@article{wang2021finetuned,
  title={A Fine-tuned Wav2vec 2.0/HuBERT Benchmark for Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding},
  author={Wang, Y. and Shenoy, A. and Thrivikraman, J.},
  journal={arXiv preprint arXiv:2111.02735},
  year={2021}
}

@article{busso2008iemocap,
  title={{IEMOCAP}: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Sungbok and Chang, Jeannette N. and Lee, Sung and Narayanan, Shrikanth S.},
  journal={Language Resources and Evaluation},
  volume={42},
  number={4},
  pages={335--359},
  year={2008}
}

@inproceedings{poria2017context,
  title={Context-dependent sentiment analysis in user-generated videos},
  author={Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Majumder, Navonil and Zadeh, Amir and Morency, Louis-Philippe},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={873--883},
  year={2017}
}

@article{tripathi2018multi,
  title={Multi-modal emotion recognition on IEMOCAP dataset using deep learning},
  author={Tripathi, Sagar and Beigi, Homayoon S.},
  journal={arXiv preprint arXiv:1804.05788},
  year={2018}
}

@inproceedings{garcia2013dynamic,
  title={Dynamic physiological signal analysis based on Fisher kernels for emotion recognition},
  author={Garc{\'\i}a, Hern{\'a}n and Arriaga, R. and Movellan, J. R.},
  booktitle={2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  pages={3423--3426},
  year={2013}
}

@inproceedings{kaya2015contrasting,
  title={Contrasting and combining least squares based learners for emotion recognition in the wild},
  author={Kaya, Heysem and G{\"u}rp{\i}nar, Feyzullah and Salah, Albert Ali},
  booktitle={2015 International Conference on Multimodal Interaction (ICMI)},
  pages={459--466},
  year={2015},
  organization={ACM}
}

@inproceedings{buechel2017emobank,
  title={{EmoBank}: Studying the impact of annotation perspective and representation format on dimensional emotion analysis},
  author={Buechel, Sven and Hahn, Udo},
  booktitle={EACL (European Chapter of the Association for Computational Linguistics)},
  pages={578--585},
  year={2017}
}

@article{liu2019roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Liu, Yinhan and Ott, M. and Goyal, N. and Du, J. and Joshi, M. and Chen, D. and Levy, O. and Lewis, M. and Zettlemoyer, L. and Stoyanov, V.},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{brown2020gpt3,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, G. and Askell, Amanda et al.},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{yang2021superb,
  title={{SUPERB}: Speech processing Universal PERformance Benchmark},
  author={Yang, Shu-wen and others},
  journal={arXiv preprint arXiv:2105.01051},
  year={2021}
}

@inproceedings{parthasarathy2020semi,
  title={Semi-supervised speech emotion recognition with ladder networks},
  author={Parthasarathy, S. and Busso, C.},
  booktitle={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={28},
  pages={2697--2709},
  year={2020}
}
